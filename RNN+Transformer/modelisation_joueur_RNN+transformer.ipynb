{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation joueur  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imporations des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import math\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Modele\n",
    "  \n",
    "### Bloc Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, x_to_dim, x_from_dim, hidden_dim,):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.sqrt_hidden_dim = math.sqrt(hidden_dim)\n",
    "\n",
    "        self.wq = nn.Parameter(torch.randn(hidden_dim, x_to_dim))\n",
    "        \n",
    "        self.wk = nn.Parameter(torch.randn(hidden_dim, x_from_dim))\n",
    "        self.wv = nn.Parameter(torch.randn(x_to_dim, x_from_dim))\n",
    "\n",
    "    def forward(self, x_to, x_from):\n",
    "        # x_to = [batch size, x_to_len, x_to_dim]\n",
    "        # x_from = [batch size, x_from_len, x_from_dim]\n",
    "\n",
    "        # les lettres dans les einsum :\n",
    "        # b : le batch\n",
    "        # x, y, z: la taille de l'ensemble (x_from ou x_to)\n",
    "        # i,j : les éléments des vecteurs de x_from, x_to / les éléments de ces vecteurs une fois projetés (via Wq, Wk ou Wv)\n",
    "\n",
    "        q = torch.einsum('ik,bxk->bxi',self.wq,x_to) # un tenseur de dimension (batch size, x_to_len, Dq)\n",
    "\n",
    "        k = torch.einsum('ij,bxj->bxi',self.wk,x_from) # un tenseur de dimension (batch size, x_from_len, Dk=Dq)\n",
    "        v = torch.einsum('ij,bxj->bxi',self.wv,x_from) # un tenseur de dimension (batch size, x_from_len, Dv)\n",
    "\n",
    "        e = torch.softmax(torch.einsum('bxi,byi->bxy', q, k)/self.sqrt_hidden_dim, dim=1) # un tenseur de dimension (batch size, x_to_len, x_from_len)\n",
    "\n",
    "        attention = torch.einsum('bxy,byi->bxi', e, v) # un tenseur de dimension (batch size, x_to_len, Dv)\n",
    "\n",
    "        return attention\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, x_to_dim, x_from_dim, hidden_dim, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        heads_list = []\n",
    "        for _ in range(n_heads):\n",
    "            att = Attention(x_to_dim, x_from_dim, hidden_dim)\n",
    "            heads_list.append(att)\n",
    "        \n",
    "        self.heads_list = heads_list\n",
    "        self.output_projection = nn.Parameter(torch.randn(n_heads))\n",
    "\n",
    "    def forward(self, x_to, x_from):\n",
    "        # x_to = [batch size, x_to_len, x_to_dim]\n",
    "        # x_from = [batch size, x_from_len, x_from_dim]\n",
    "        attention_list = []\n",
    "\n",
    "        for head in self.heads_list:\n",
    "            attention_list.append(head(x_to, x_from)) \n",
    "\n",
    "        concat = torch.stack(attention_list) # on obtient ainsi un tenseur représentant la concaténation des résultats des différentes \"heads\"\n",
    "\n",
    "        result = torch.einsum('hbxi,h->bxi', concat, self.output_projection)\n",
    "\n",
    "        return result\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, x_to_dim, hidden_dim, n_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.multhead = MultiHeadAttention(x_to_dim, x_to_dim, hidden_dim, n_heads)\n",
    "    \n",
    "    def forward(self, x_to):\n",
    "        return self.multhead(x_to, x_to)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LayerNorm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm_x = torch.norm(x, dim=1).unsqueeze(1).expand_as(x)\n",
    "\n",
    "        return x/norm_x\n",
    "\n",
    "class FFN(nn.Sequential):\n",
    "    def __init__(self, input_dim, dropout_rate=0.1, expansion_factor=2):\n",
    "        super(FFN, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_dim, input_dim*expansion_factor)\n",
    "        self.dropout_layer = nn.Dropout(p = dropout_rate)\n",
    "        self.output_layer = nn.Linear(input_dim*expansion_factor, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = nn.LeakyReLU(negative_slope=0.1)(self.dropout_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, data_dim, hidden_dim, n_heads, dropout_rate=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "\n",
    "        self.bloc_self_attention = MultiHeadSelfAttention(data_dim, hidden_dim, n_heads)\n",
    "\n",
    "        self.bloc_normalization_1 = LayerNorm()\n",
    "\n",
    "        self.bloc_FFN = FFN(data_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.bloc_normalization_2 = LayerNorm()\n",
    "        # It's useless to use 2 LayerNorm, cause they are the same. \n",
    "        # Yet, because it's my first transformer,\n",
    "        # I will keep both of them for clarity in my mind\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch size, x_len, hidden dim]\n",
    "        identity = x\n",
    "        x = self.bloc_self_attention(x)\n",
    "        x = self.bloc_normalization_1(x+identity)\n",
    "\n",
    "        identity = x\n",
    "        x = self.bloc_FFN(x)\n",
    "        x = self.bloc_normalization_2(x+identity)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, hidden_dim, max_len, const = 10000):\n",
    "        super(SinusoidalPositionalEncoding, self).__init__()\n",
    "\n",
    "        self.pe = torch.zeros(max_len, hidden_dim)\n",
    "\n",
    "        for i in range(max_len):\n",
    "            for j in range(hidden_dim):\n",
    "                if j%2==0:\n",
    "                    self.pe[i, j] = math.sin(i/(const**(j/hidden_dim)))\n",
    "                else:\n",
    "                    self.pe[i, j] = math.cos(i/(const**((j-1)/hidden_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch size, len_x, dim_vect_de_x]\n",
    "        dim_batch = x.size(0) # dimension du batch\n",
    "        for k in range(dim_batch):\n",
    "            x[k] += self.pe[:x[k].size(0),:] # on somme le tenseur PE sur chaque élément du batch\n",
    "        return x\n",
    "\n",
    "class LearnedPositionalEncoding(nn.Module):\n",
    "    def __init__(self, hidden_dim, max_len):\n",
    "        super(LearnedPositionalEncoding, self).__init__()\n",
    "\n",
    "        self.pe = nn.Parameter(torch.randn(max_len, hidden_dim))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        dim_batch = x.size(0) # dimension du batch\n",
    "        for k in range(dim_batch):\n",
    "            x[k] += self.pe[:x[k].size(0),:] # on somme le tenseur PE sur chaque élément du batch\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, data_dim,  hidden_dim, n_heads, n_layers, dropout_rate=0.1, positional_encoding=\"sinusoidal\", max_len=1000):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        if positional_encoding == \"sinusoidal\":\n",
    "            self.layer_positional_encoding = SinusoidalPositionalEncoding(data_dim, max_len)\n",
    "        else:\n",
    "            self.layer_positional_encoding = LearnedPositionalEncoding(data_dim, max_len)\n",
    "        \n",
    "        self.bloc_transformer_list = nn.ModuleList([TransformerEncoderBlock(data_dim, hidden_dim, n_heads, dropout_rate) for i in range(n_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_positional_encoding(x)\n",
    "\n",
    "        for transformer_block in self.bloc_transformer_list:\n",
    "            x = transformer_block(x)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ca marche un jour, on peut rajouter dans l'état mémoire (actuellement que les 9 joueurs) une mémoire du board\n",
    "with open(\"./data_RNN+transformer\", \"rb\") as temp:\n",
    "    data = pickle.load(temp)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layers_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(in_features=layers_sizes[i], out_features=layers_sizes[i+1]) for i in range(len(layers_sizes)-1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = nn.LeakyReLU()(layer(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PlayerModel(nn.Module):\n",
    "    def __init__(self, dim_stat_adversaire, dim_representation_joueur, dim_representation_carte=2):\n",
    "        super(PlayerModel, self).__init__()\n",
    "\n",
    "        self.representation_initiale_joueur = nn.Parameter(torch.randn(dim_representation_joueur))\n",
    "        self.representation_joueur_couche = nn.Parameter(torch.randn(dim_representation_joueur))\n",
    "\n",
    "        ## Réseau de changement de la représentation d'un aversaire en fonction de son action des autres adversaires :\n",
    "        self.repr_adversaire = MLP(layers_sizes = [2 + dim_stat_adversaire + 9*dim_representation_joueur, 32, dim_representation_joueur])\n",
    "\n",
    "        ## Réseaux de changement de la représentation des joueurs après l'arrivée de nouvelles cartes sur le Board\n",
    "        self.new_board = MLP(layers_sizes = [5*dim_representation_carte + 2*dim_representation_carte + dim_representation_joueur, 64, 16, dim_representation_joueur])\n",
    "        self.remplace_carte = torch.tensor([-1]*dim_representation_carte)\n",
    "        # -> 5 cartes : board, 2 cartes : cartes de 'IlxxxlI' si il s'agit d'un adversaire, rien sinon\n",
    "\n",
    "        self.transformer_bloc = TransformerEncoder(dim_representation_joueur, 16, 6, 3, positional_encoding='learned', max_len=9)\n",
    "\n",
    "        self.finalMLP = MLP(layers_sizes=[dim_representation_joueur+ 5*dim_representation_carte + 2*dim_representation_carte, 32, 32, 3])\n",
    "\n",
    "\n",
    "    def forward(self, batch_x):\n",
    "        ly = []\n",
    "        for ind in batch_x:\n",
    "            game_id, sequence, stats_joueurs, ind_hero, joueurs_presents, cartes_hero = data[ind][0]\n",
    "            # format de la sequence ? \n",
    "            # liste d'actions : ('indice joueur', 'action', 'sizing') ou ('board')\n",
    "            cartes_hero = torch.tensor(cartes_hero)\n",
    "            board = torch.stack([self.remplace_carte] * 5)\n",
    "            joueurs = torch.stack([self.representation_initiale_joueur.clone() if joueurs_presents[ind] else self.representation_joueur_couche for ind in range(9)])\n",
    "\n",
    "            for token in sequence:\n",
    "                if len(token)==3:\n",
    "                    ind, action, sizing = token\n",
    "                    if action == -1: # fold\n",
    "                        joueurs[ind, :] = self.representation_joueur_couche\n",
    "                        joueurs_presents[ind] = False\n",
    "                    else:\n",
    "                        input = torch.cat((torch.flatten(joueurs[ind:, :]), torch.flatten(joueurs[:ind, :]),torch.tensor(stats_joueurs[ind]).unsqueeze(dim=0), torch.tensor(action).unsqueeze(dim=0), torch.tensor(sizing).unsqueeze(dim=0)))\n",
    "                        joueurs[ind, :] = self.repr_adversaire(input.unsqueeze(0))\n",
    "                else:\n",
    "                    if token[6]<-0.5:\n",
    "                        board = torch.cat((torch.tensor(token[:6]), torch.tensor(self.remplace_carte), torch.tensor(self.remplace_carte)))\n",
    "                    elif token[8]<-0.5:\n",
    "                        board = torch.cat((torch.tensor(token[:8]), self.remplace_carte))\n",
    "                    else:\n",
    "                        board = torch.tensor(token)\n",
    "\n",
    "                    for ind in range(9):\n",
    "                        if ind!=ind_hero:\n",
    "                            cartes = cartes_hero\n",
    "                        else:\n",
    "                            cartes = torch.cat((self.remplace_carte, self.remplace_carte)).flatten()\n",
    "                        \n",
    "                        if joueurs_presents[ind]:\n",
    "                            input = torch.cat((board, cartes, joueurs[ind,:].squeeze()))\n",
    "                            joueurs[ind,:] = self.new_board(input.unsqueeze(0))\n",
    "\n",
    "            y = self.transformer_bloc(joueurs.unsqueeze(0))[0,ind_hero,:]\n",
    "\n",
    "            ly.append(nn.Softmax()(self.finalMLP(torch.cat((y, board.flatten(), cartes_hero.flatten())).unsqueeze(0))))\n",
    "        return torch.stack(ly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "### Fonctions annexes\n",
    "\n",
    "Datasets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((808937195, [(4, 0, 0.5), (6, 0, 1.0), (7, -1, 0), (8, -1, 0), (0, 3, 2.3), (4, -1, 0), (6, 1, 1.3), [4.0, 0.0, 2.0, 0.0, 2.0, 3.0, -1.0, -1.0, -1.0, -1.0], (6, 0, 0), (0, 0, 0), [4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 5.0, 2.0, -1.0, -1.0], (6, 0, 0)], [28.73, 0, 0, 0, 40.0, 0, 44.14, 94.65, 50.66], 0, [True, False, False, False, True, False, True, True, True], [14.0, 0.0, 8.0, 1.0]), [0.0, 0.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data_RNN+transformer\", \"rb\") as temp:\n",
    "    data = pickle.load(temp)\n",
    "\n",
    "print(data[53])\n",
    "# il y a 55924 éléments\n",
    "class PlayerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        output_data = self.data[idx][1]\n",
    "        return torch.tensor(idx), torch.tensor(output_data)\n",
    "\n",
    "\n",
    "training_data = PlayerDataset(data[:50000])\n",
    "test_data = PlayerDataset(data[50000:55924])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success_rate_2(model,test_data):\n",
    "    loader = torch.utils.data.DataLoader(test_data, batch_size=len(test_data))\n",
    "    with torch.no_grad():\n",
    "        bonne_identification = 0\n",
    "\n",
    "        for x_batch, y_batch in loader:\n",
    "            \n",
    "            y_pred = model(x_batch).squeeze()\n",
    "\n",
    "            for ind in range(len(y_pred)):\n",
    "                \n",
    "                if y_batch[ind][np.argmax(y_pred[ind])] >0.5:\n",
    "                    bonne_identification += 1\n",
    "            return(bonne_identification/len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainer(train_data, test_data, model, loss_fn,epoch=10,batch_size=1,rate=1e-4):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=rate)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "    for t in trange(epoch, desc='epochs'):\n",
    "        for x_batch, y_batch in tqdm(loader):\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch).squeeze(dim=1)\n",
    "            if isinstance(loss_fn, torch.nn.MSELoss):\n",
    "                y_batch = y_batch.float()\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(success_rate_2(model, test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modele de base : 196K parametres\n",
    "# modele suivant : 310K parametres\n",
    "modelisation_joueur = PlayerModel(1, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\augus_zcrxu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "C:\\Users\\augus_zcrxu\\AppData\\Local\\Temp\\ipykernel_17804\\2202395439.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  board = torch.cat((torch.tensor(token[:6]), torch.tensor(self.remplace_carte), torch.tensor(self.remplace_carte)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1850101282916948\n"
     ]
    }
   ],
   "source": [
    "print(success_rate_2(modelisation_joueur, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\augus_zcrxu\\AppData\\Local\\Temp\\ipykernel_17804\\2202395439.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  board = torch.cat((torch.tensor(token[:6]), torch.tensor(self.remplace_carte), torch.tensor(self.remplace_carte)))\n",
      "100%|██████████| 782/782 [21:58<00:00,  1.69s/it]\n",
      "epochs:  10%|█         | 1/10 [22:43<3:24:35, 1363.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5268399729912221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [21:49<00:00,  1.67s/it]\n",
      "epochs:  20%|██        | 2/10 [45:15<3:00:55, 1356.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525320729237002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [21:23<00:00,  1.64s/it]\n",
      "epochs:  30%|███       | 3/10 [1:07:20<2:36:36, 1342.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525151924375422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [21:26<00:00,  1.65s/it]\n",
      "epochs:  40%|████      | 4/10 [1:29:29<2:13:41, 1336.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525151924375422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [26:03<00:00,  2.00s/it]\n",
      "epochs:  50%|█████     | 5/10 [1:56:22<1:59:42, 1436.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524983119513842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 85/782 [12:32:55<102:54:02, 531.48s/it]\n",
      "epochs:  50%|█████     | 5/10 [14:29:18<14:29:18, 10431.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelisation_joueur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(train_data, test_data, model, loss_fn, epoch, batch_size, rate)\u001b[0m\n\u001b[0;32m     14\u001b[0m         y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(success_rate_2(model, test_data))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer(training_data, test_data, modelisation_joueur, loss_fn = nn.CrossEntropyLoss(), epoch=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
